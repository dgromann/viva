{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgromann/viva/blob/master/NLP_syntactic_processing_miniexample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcnUc0sL9433",
        "colab_type": "text"
      },
      "source": [
        "##VIVA Summer School - Basic syntactic NLP processing\n",
        "\n",
        "This is a very short intro into building an NLP pipeline with [SpaCy](https://nlpforhackers.io/complete-guide-to-spacy/) - a popular NLP library and toolkit that represents a recent alternative to the conventional Natural Language Toolkit (NLTK) in Python. \n",
        "\n",
        "First we need to download the English version of spacy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79jiRQIw94Bk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOvb9Vy1-NYU",
        "colab_type": "text"
      },
      "source": [
        "# Tokenization\n",
        "Next, we will import the SpaCy library to python and give it a first statement to tokenize. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a440aXyf-XdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "doc = nlp(\"Welcome to the NLP pipeline in SpaCy!\")\n",
        "for token in doc:\n",
        "    print('\"' + token.text + '\"', token.idx)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cktd3je2-rZ5",
        "colab_type": "text"
      },
      "source": [
        "# Sentence detection\n",
        "\n",
        "We can also detect individual sentences in a longer text. The good thing about NLTK is that it comes with a number of preprocessed and cleaned corpora, such as the Brown corpus. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCr0HhF0-qo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "#only for the first time\n",
        "nltk.download('gutenberg')\n",
        "from nltk.corpus import gutenberg as gutenberg\n",
        "\n",
        "gutenberg.fileids()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSx4iqinAR86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "excerpt = gutenberg.raw('austen-sense.txt')[0:1000]\n",
        "print(excerpt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJE6QAx7Q7BT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsZHxK2kB7fx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_text = nlp(excerpt)\n",
        "for sent in processed_text.sents: \n",
        "  print(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_NUxbObDqPO",
        "colab_type": "text"
      },
      "source": [
        "# POS Tagging\n",
        "\n",
        "Part-of-speech tagging is the process of identifying word classes for each individual word. \n",
        "\n",
        "For instance \"NN\" refers to a noun singular, \"CC\" denotes a coordination, etc. The whole collection of highly conventional tags can be found in the [Penn Treebank listing](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vn3jvSEDr4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print([(token.text, token.tag_) for token in processed_text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcr9FOK-EXN1",
        "colab_type": "text"
      },
      "source": [
        "Which process is the following? Which elements of the text are being extracted?\n",
        "\n",
        "GPE, for instance, denotes geopolitical entity, FAC refers to \"Buildings, airports, highways, bridges, etc.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYORqBbeEWcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ent in processed_text.ents:\n",
        "    print(ent.text, ent.label_)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02se4DGqFiJi",
        "colab_type": "text"
      },
      "source": [
        "And its visual representation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ND9kb0FFcIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy import displacy\n",
        "displacy.render(processed_text, style='ent', jupyter=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWNSjhIdFpst",
        "colab_type": "text"
      },
      "source": [
        "# Dependency Parsing \n",
        "\n",
        "What can we learn from dependency parsing?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v3gZMOpFtwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "displacy.render(processed_text[13:24], style='dep', jupyter=True, options={'distance': 90})"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}